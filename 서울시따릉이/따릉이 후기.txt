후기

다른 활동을 하다가 .venv 파일이 덮어져서 설정이 다 날아가 복구하는데 시간이 좀 걸렸다.


어쨋거나 따릉이 데이터를 처리하면서 느꼈던 점은

1. 인간이 할 수 있는 데이터 가공 처리가 있고   
    -> 예를 들자면 따릉이를 어떨 때 많이 탈까 ..
        1. 일교차가 너무 클때 (high_temp - low_temp)
        2. 고온다습할때 (high_temp * humidity)
        3. 춥고 바람 많이불때 (low_temp * wind_speed)
        4. 비오고 흐릴때 (precipitation_form * sky_condition)

2. 컴퓨터의 성능에 의존하는 방법도 있다는 것을 알았다.
    -> 예를 들자면 특성들을 모두 곱해버려서 특성의 수를 크게 늘리는 방법 등 ..


오버피팅이 되지 않을까~ 했는데
이번 데이터의 경우에는 나름 도움이 된 것 같다.
-> 실제로 궁금해서 이전 데이터셋인 Titanic에서 해봤는데 큰 도움이 안됐다.

1번과 2번을 합했을 때 가장 최고점이 나왔다.
여기서 상관관계 기반으로 한번 더 전처리를 하면 더 높은 점수가 나올 수 있을 것 같다.



외에도 데이터를 시각화 하는데 노력을 기울였다.
데이터를 시각화하고 이를 어떻게 분석해야 할지 집중했고, 직관적이라 개선점이 좀 더 잘 보였다.

히트맵을 그려서 상관관계가 높은 변수들끼리 묶어서 생각해보기도 하고,
결측치를 처리할 때도 마찬가지로 상관관계가 높은 변수들을 기반으로 채우기도 했다.

참고로 이걸 하면서 폴더 내에 있는 model_search_Algorithm 코드를 찾았는데,
모델 뭐쓰지~ 할때 쓰면 정말 편하다.